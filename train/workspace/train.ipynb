{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eba7ea5-0c52-4112-9b6a-22d5c6ff3089",
   "metadata": {},
   "source": [
    "Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b616a5a3-4fc9-4074-b80d-c8e02cf29cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0dbd99-8705-4a15-a011-ce2fa3d6ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in taxi data frame\n",
    "dfTaxi = pd.read_csv(\"2018_Yellow_Taxi_Trip_Data.csv\", nrows=1_000, header=0)\n",
    "\n",
    "# initialize column names\n",
    "column_names = ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance',\n",
    "                'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount',\n",
    "                'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount']\n",
    "\n",
    "# reread dataframe to reinitialize columns\n",
    "dfTaxi = pd.read_csv('2018_Yellow_Taxi_Trip_Data.csv', header=None, names=column_names, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df1248a8-990f-4253-b71f-9e6bf7908527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>03/31/2018 03:45:57 PM</td>\n",
       "      <td>03/31/2018 03:50:56 PM</td>\n",
       "      <td>0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>239.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>03/31/2018 03:53:58 PM</td>\n",
       "      <td>03/31/2018 03:56:36 PM</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>239.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>03/31/2018 03:59:56 PM</td>\n",
       "      <td>03/31/2018 04:08:31 PM</td>\n",
       "      <td>0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>239.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>03/31/2018 03:05:51 PM</td>\n",
       "      <td>03/31/2018 03:29:28 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>4.63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>229.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>03/31/2018 03:06:04 PM</td>\n",
       "      <td>03/31/2018 03:17:37 PM</td>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>100.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID    tpep_pickup_datetime   tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  03/31/2018 03:45:57 PM  03/31/2018 03:50:56 PM                0   \n",
       "1         1  03/31/2018 03:53:58 PM  03/31/2018 03:56:36 PM                0   \n",
       "2         1  03/31/2018 03:59:56 PM  03/31/2018 04:08:31 PM                0   \n",
       "3         2  03/31/2018 03:05:51 PM  03/31/2018 03:29:28 PM                1   \n",
       "4         2  03/31/2018 03:06:04 PM  03/31/2018 03:17:37 PM                1   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           0.70         1.0                  N         239.0         239.0   \n",
       "1           0.20         1.0                  N         239.0         239.0   \n",
       "2           1.70         1.0                  N         239.0         141.0   \n",
       "3           4.63         1.0                  N         229.0         249.0   \n",
       "4           0.98         1.0                  N         100.0         246.0   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0           2.0          5.5    0.0      0.5        0.00           0.0   \n",
       "1           2.0          3.5    0.0      0.5        0.00           0.0   \n",
       "2           2.0          8.0    0.0      0.5        0.00           0.0   \n",
       "3           1.0         19.5    0.0      0.5        4.06           0.0   \n",
       "4           1.0          8.5    0.0      0.5        1.86           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  \n",
       "0                    0.3          6.30  \n",
       "1                    0.3          4.30  \n",
       "2                    0.3          8.80  \n",
       "3                    0.3         24.36  \n",
       "4                    0.3         11.16  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTaxi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b02b8e11-ee21-411d-8264-c51878822ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event ID</th>\n",
       "      <th>Event Name</th>\n",
       "      <th>Start Date/Time</th>\n",
       "      <th>End Date/Time</th>\n",
       "      <th>Event Agency</th>\n",
       "      <th>Event Type</th>\n",
       "      <th>Event Borough</th>\n",
       "      <th>Event Location</th>\n",
       "      <th>Event Street Side</th>\n",
       "      <th>Street Closure Type</th>\n",
       "      <th>Community Board</th>\n",
       "      <th>Police Precinct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>368421</td>\n",
       "      <td>Big Apple Circus</td>\n",
       "      <td>11/18/2017 07:00:00 PM</td>\n",
       "      <td>11/18/2017 08:00:00 PM</td>\n",
       "      <td>Parks Department</td>\n",
       "      <td>Special Event</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Damrosch Park: Damrosch Park ,Damrosch Park: T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7,</td>\n",
       "      <td>20,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>330050</td>\n",
       "      <td>Mt. Eden Farmer's Market</td>\n",
       "      <td>11/16/2017 08:00:00 AM</td>\n",
       "      <td>11/16/2017 04:00:00 PM</td>\n",
       "      <td>Parks Department</td>\n",
       "      <td>Special Event</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Mount Eden Malls: Mount Eden Malls</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4,</td>\n",
       "      <td>44,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>314111</td>\n",
       "      <td>Columbia  Greenmarket Thursday</td>\n",
       "      <td>11/21/2017 08:00:00 AM</td>\n",
       "      <td>11/21/2017 05:00:00 PM</td>\n",
       "      <td>Street Activity Permit Office</td>\n",
       "      <td>Farmers Market</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>BROADWAY between WEST  114 STREET and WEST  1...</td>\n",
       "      <td>East</td>\n",
       "      <td>Sidewalk and Curb Lane Closure</td>\n",
       "      <td>9,</td>\n",
       "      <td>26,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>369850</td>\n",
       "      <td>Lawn Maintenance</td>\n",
       "      <td>11/23/2017 12:00:00 AM</td>\n",
       "      <td>11/23/2017 11:58:00 PM</td>\n",
       "      <td>Parks Department</td>\n",
       "      <td>Construction</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Madison Square Park: Center Lawn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,</td>\n",
       "      <td>13,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>335783</td>\n",
       "      <td>October, November December model aircraft flying</td>\n",
       "      <td>11/22/2017 09:00:00 AM</td>\n",
       "      <td>11/22/2017 08:00:00 PM</td>\n",
       "      <td>Parks Department</td>\n",
       "      <td>Special Event</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>LaTourette Park &amp; Golf Course: Model Airplane ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2,</td>\n",
       "      <td>122,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Event ID                                        Event Name  \\\n",
       "0    368421                                  Big Apple Circus   \n",
       "1    330050                          Mt. Eden Farmer's Market   \n",
       "2    314111                    Columbia  Greenmarket Thursday   \n",
       "3    369850                                  Lawn Maintenance   \n",
       "4    335783  October, November December model aircraft flying   \n",
       "\n",
       "          Start Date/Time           End Date/Time  \\\n",
       "0  11/18/2017 07:00:00 PM  11/18/2017 08:00:00 PM   \n",
       "1  11/16/2017 08:00:00 AM  11/16/2017 04:00:00 PM   \n",
       "2  11/21/2017 08:00:00 AM  11/21/2017 05:00:00 PM   \n",
       "3  11/23/2017 12:00:00 AM  11/23/2017 11:58:00 PM   \n",
       "4  11/22/2017 09:00:00 AM  11/22/2017 08:00:00 PM   \n",
       "\n",
       "                    Event Agency      Event Type  Event Borough  \\\n",
       "0               Parks Department   Special Event      Manhattan   \n",
       "1               Parks Department   Special Event          Bronx   \n",
       "2  Street Activity Permit Office  Farmers Market      Manhattan   \n",
       "3               Parks Department    Construction      Manhattan   \n",
       "4               Parks Department   Special Event  Staten Island   \n",
       "\n",
       "                                      Event Location Event Street Side  \\\n",
       "0  Damrosch Park: Damrosch Park ,Damrosch Park: T...               NaN   \n",
       "1                Mount Eden Malls: Mount Eden Malls                NaN   \n",
       "2   BROADWAY between WEST  114 STREET and WEST  1...              East   \n",
       "3                  Madison Square Park: Center Lawn                NaN   \n",
       "4  LaTourette Park & Golf Course: Model Airplane ...               NaN   \n",
       "\n",
       "               Street Closure Type Community Board Police Precinct  \n",
       "0                              NaN             7,             20,   \n",
       "1                              NaN             4,             44,   \n",
       "2  Sidewalk and Curb Lane Closure              9,             26,   \n",
       "3                              NaN             5,             13,   \n",
       "4                              NaN             2,            122,   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in event data\n",
    "dfEvent = pd.read_csv(\"NYC_Permitted_Event_Information_-_Historical.csv\", nrows=1_000)\n",
    "dfEvent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a0b39d3-279c-45ba-a54e-3dac8ecad874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Event ID', 'Event Name', 'Start Date/Time', 'End Date/Time',\n",
       "       'Event Agency', 'Event Type', 'Event Borough', 'Event Location',\n",
       "       'Event Street Side', 'Street Closure Type', 'Community Board',\n",
       "       'Police Precinct'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfEvent.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338af064-d186-48ab-baf1-6b04eaf7de66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTaxi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7cc2570-36fb-4b82-9707-d056a5cff01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{40.0: 'St. James Theatre: 246 West 44th Street ', 79.0: 'St. James Theatre: 246 West 44th Street ', 107.0: 'St. James Theatre: 246 West 44th Street ', 114.0: 'East River Park: Amphitheater ', 132.0: 'St. James Theatre: 246 West 44th Street ', 137.0: 'East River Park: Amphitheater ', 140.0: 'East River Park: Amphitheater ', 141.0: 'East River Park: Amphitheater ', 142.0: 'East River Park: Amphitheater ', 146.0: 'St. James Theatre: 246 West 44th Street ', 148.0: 'St. James Theatre: 246 West 44th Street ', 161.0: 'East River Park: Amphitheater ', 163.0: 'St. James Theatre: 246 West 44th Street ', 164.0: 'St. James Theatre: 246 West 44th Street ', 170.0: 'St. James Theatre: 246 West 44th Street ', 193.0: 'East River Park: Amphitheater ', 229.0: 'East River Park: Amphitheater ', 230.0: 'St. James Theatre: 246 West 44th Street ', 231.0: 'St. James Theatre: 246 West 44th Street ', 233.0: 'East River Park: Amphitheater ', 234.0: 'St. James Theatre: 246 West 44th Street ', 236.0: 'St. James Theatre: 246 West 44th Street ', 237.0: 'East River Park: Amphitheater ', 255.0: 'St. James Theatre: 246 West 44th Street ', 263.0: 'East River Park: Amphitheater '}\n"
     ]
    }
   ],
   "source": [
    "#Convert to datetime\n",
    "dfTaxi['tpep_pickup_datetime'] = pd.to_datetime(dfTaxi['tpep_pickup_datetime'])\n",
    "dfEvent['Start Date/Time'] = pd.to_datetime(dfEvent['Start Date/Time'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "dfEvent['End Date/Time'] = pd.to_datetime(dfEvent['End Date/Time'], format='%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "# Initialize empty list to collect matches\n",
    "matches = []\n",
    "\n",
    "# For each event, find taxi pickups during its time window\n",
    "for _, event in dfEvent.iterrows():\n",
    "    start = event['Start Date/Time']\n",
    "    end = event['End Date/Time']\n",
    "    location = event['Event Location']\n",
    "    \n",
    "    # Filter pickups during the event\n",
    "    mask = (dfTaxi['tpep_pickup_datetime'] >= start) & (dfTaxi['tpep_pickup_datetime'] <= end)\n",
    "    pickups_during_event = dfTaxi.loc[mask, ['PULocationID']].copy()\n",
    "    pickups_during_event['event_location'] = location\n",
    "    \n",
    "    matches.append(pickups_during_event)\n",
    "\n",
    "# Concatenate all matched pickups\n",
    "dfMatched = pd.concat(matches)\n",
    "\n",
    "# Group by PULocationID and pick the most common event location\n",
    "pu_to_event_dict = dfMatched.groupby('PULocationID')['event_location'].agg(lambda x: x.mode().iloc[0]).to_dict()\n",
    "print(pu_to_event_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71c868eb-f620-4f12-96b8-51c76f833e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pickup_bin  num_trips\n",
      "0   2008-12-31 13:00:00          1\n",
      "1   2018-03-03 15:15:00          1\n",
      "2   2018-03-03 16:30:00          1\n",
      "3   2018-03-03 19:00:00          1\n",
      "4   2018-03-03 20:30:00          1\n",
      "..                  ...        ...\n",
      "175 2018-04-01 17:00:00         38\n",
      "176 2018-04-01 17:45:00          1\n",
      "177 2018-04-01 20:15:00          1\n",
      "178 2018-04-01 23:30:00          1\n",
      "179 2018-04-01 23:45:00          2\n",
      "\n",
      "[180 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "dfTaxi['pickup_bin'] = dfTaxi['tpep_pickup_datetime'].dt.floor('15min')\n",
    "trip_counts = dfTaxi.groupby('pickup_bin').size().reset_index(name='num_trips')\n",
    "\n",
    "print(trip_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96445de5-4489-4744-b35a-ad4dc6ad81d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pickup_bin  num_trips  has_event_x  has_event_y  has_event\n",
      "0   2008-12-31 13:00:00          1          0.0          NaN        0.0\n",
      "1   2018-03-03 15:15:00          1          1.0          1.0        1.0\n",
      "2   2018-03-03 16:30:00          1          1.0          1.0        1.0\n",
      "3   2018-03-03 19:00:00          1          1.0          1.0        1.0\n",
      "4   2018-03-03 20:30:00          1          1.0          1.0        1.0\n",
      "..                  ...        ...          ...          ...        ...\n",
      "175 2018-04-01 17:00:00         38          0.0          NaN        0.0\n",
      "176 2018-04-01 17:45:00          1          0.0          NaN        0.0\n",
      "177 2018-04-01 20:15:00          1          0.0          NaN        0.0\n",
      "178 2018-04-01 23:30:00          1          0.0          NaN        0.0\n",
      "179 2018-04-01 23:45:00          2          0.0          NaN        0.0\n",
      "\n",
      "[180 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess event data\n",
    "dfEvent['time_bin'] = dfEvent['Start Date/Time'].dt.floor('15min')\n",
    "dfEvent['event_duration'] = (dfEvent['End Date/Time'] - dfEvent['Start Date/Time']).dt.total_seconds() / 60\n",
    "\n",
    "# Expand events to cover all 15-minute they span\n",
    "event_bins = []\n",
    "for _, row in dfEvent.iterrows():\n",
    "    bins = pd.date_range(start=row['Start Date/Time'], end=row['End Date/Time'], freq='15min')\n",
    "    for b in bins:\n",
    "        event_bins.append(b)\n",
    "event_bins = pd.Series(event_bins).drop_duplicates()\n",
    "\n",
    "# associate the bins with events\n",
    "event_bins_df = pd.DataFrame({'pickup_bin': event_bins, 'has_event': 1})\n",
    "\n",
    "# Merge with trip_counts on the pickup_bin\n",
    "trip_counts = trip_counts.merge(event_bins_df, on='pickup_bin', how='left', suffixes=('_trip', '_event'))\n",
    "\n",
    "# Handle the merged columns\n",
    "# If the 'has_event_event' column exists, fill NaN values with 0 and drop redundant columns\n",
    "trip_counts['has_event'] = trip_counts['has_event_event'].fillna(0)  # Fill NaNs with 0\n",
    "trip_counts.drop(columns=['has_event_trip', 'has_event_event'], inplace=True)  # Drop redundant columns\n",
    "\n",
    "# View the final trip_counts dataframe\n",
    "print(trip_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "62573c59-8a99-44cd-824c-038c3d5ce077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e03a176-ce45-4271-881e-257b7fe85025",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# initialize and train the model \u001b[39;00m\n\u001b[32m      5\u001b[39m model = LinearRegression()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[32m      9\u001b[39m y_pred = model.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/sklearn/linear_model/_base.py:601\u001b[39m, in \u001b[36mLinearRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    597\u001b[39m n_jobs_ = \u001b[38;5;28mself\u001b[39m.n_jobs\n\u001b[32m    599\u001b[39m accept_sparse = \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.positive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcoo\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m601\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    609\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    611\u001b[39m has_sw = sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/sklearn/utils/validation.py:2961\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2959\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2960\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2961\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2962\u001b[39m     out = X, y\n\u001b[32m   2964\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/sklearn/utils/validation.py:1387\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1368\u001b[39m ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m   1370\u001b[39m X = check_array(\n\u001b[32m   1371\u001b[39m     X,\n\u001b[32m   1372\u001b[39m     accept_sparse=accept_sparse,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1384\u001b[39m     input_name=\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1385\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1387\u001b[39m y = \u001b[43m_check_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[43m=\u001b[49m\u001b[43my_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1389\u001b[39m check_consistent_length(X, y)\n\u001b[32m   1391\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/sklearn/utils/validation.py:1397\u001b[39m, in \u001b[36m_check_y\u001b[39m\u001b[34m(y, multi_output, y_numeric, estimator)\u001b[39m\n\u001b[32m   1395\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Isolated part of check_X_y dedicated to y validation\"\"\"\u001b[39;00m\n\u001b[32m   1396\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m multi_output:\n\u001b[32m-> \u001b[39m\u001b[32m1397\u001b[39m     y = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43my\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1407\u001b[39m     estimator_name = _check_estimator_name(estimator)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/sklearn/utils/validation.py:1107\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1102\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m expected <= 2.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1103\u001b[39m         % (array.ndim, estimator_name)\n\u001b[32m   1104\u001b[39m     )\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1107\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1115\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1116\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/sklearn/utils/validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/sklearn/utils/validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "# Split data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# initialize and train the model \n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee200d0-a7a9-41bc-9763-ca3c32d14eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
